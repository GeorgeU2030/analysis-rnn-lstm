{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD3u0N8OHR2BWcS1ZdbJNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeU2030/analysis-rnn-lstm/blob/main/code-implementation/RNN_LSTM_TI2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment analysis - RNN and LSTM.\n",
        "\n",
        "Members\n",
        "\n",
        "- Luis Botero\n",
        "- Juan Medina\n",
        "- George Trujillo"
      ],
      "metadata": {
        "id": "eaUvW-UHtAMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Gather the dataset for sentiment analysis from the UCI Machine Learning Repository, specifically\n",
        "the Sentiment Labelled Sentences Data Set"
      ],
      "metadata": {
        "id": "FnidrNccQzat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the file from the download site\n",
        "!wget https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
        "\n",
        "# Unzip the obtained file\n",
        "!unzip sentiment+labelled+sentences.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hZnPbwQywX",
        "outputId": "b2fe0a56-806b-4220-8c0a-9e44161356d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 18:15:53--  https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘sentiment+labelled+sentences.zip’\n",
            "\n",
            "sentiment+labelled+     [ <=>                ]  82.21K   488KB/s    in 0.2s    \n",
            "\n",
            "2023-11-21 18:15:54 (488 KB/s) - ‘sentiment+labelled+sentences.zip’ saved [84188]\n",
            "\n",
            "Archive:  sentiment+labelled+sentences.zip\n",
            "   creating: sentiment labelled sentences/\n",
            "  inflating: sentiment labelled sentences/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/sentiment labelled sentences/\n",
            "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: __MACOSX/._sentiment labelled sentences  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocess the text data, including tokenization, lowercasing, and removing stopwords. Prepare the\n",
        "data for supervised learning (use NLTK)."
      ],
      "metadata": {
        "id": "XNbnxgJZdda3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# We load the data from the websites\n",
        "# amazon\n",
        "df_amazon = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep='\\t', header=None)\n",
        "df_amazon.columns = ['sentence', 'label']\n",
        "\n",
        "# imdb\n",
        "df_imdb = pd.read_csv('sentiment labelled sentences/imdb_labelled.txt', sep='\\t', header=None)\n",
        "df_imdb.columns = ['sentence', 'label']\n",
        "\n",
        "# yelp\n",
        "df_yelp = pd.read_csv('sentiment labelled sentences/yelp_labelled.txt', sep='\\t', header=None)\n",
        "df_yelp.columns = ['sentence', 'label']\n",
        "\n",
        "# We mix the dataframes, reload the index, for no obtain duplicate indexes\n",
        "df = pd.concat([df_amazon, df_imdb, df_yelp], ignore_index=True)\n",
        "\n",
        "# We tokenize each sentence into individual words, convert words to lowercase, and remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['sentence'] = df['sentence'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.isalnum() and word.lower() not in stop_words]))\n",
        "\n",
        "print(df['sentence'])\n"
      ],
      "metadata": {
        "id": "NV-rUa39dbw7",
        "outputId": "50b5c3c7-3ca5-4500-d399-f386f2c91c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                   way plug us unless go\n",
            "1                                          good excellent\n",
            "2                                                   great\n",
            "3                   tied charger conversations lasting 45\n",
            "4                                                     mic\n",
            "                              ...                        \n",
            "2743                            think food flavor texture\n",
            "2744                                   appetite instantly\n",
            "2745                           overall impressed would go\n",
            "2746           whole experience think go ninja sushi next\n",
            "2747    wasted enough life poured salt wound drawing t...\n",
            "Name: sentence, Length: 2748, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We prepare the data for supervised learning\n",
        "# We divide the data in training and test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sentence'], df['label'], test_size=0.3, random_state=123)\n",
        "\n",
        "# Convert the text to numerical characteristics\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Convert the categorical to numerical characteristics\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n"
      ],
      "metadata": {
        "id": "9iEFgS87vgPq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement a DummyClassifier. Train the model on the preprocessed data and evaluate its\n",
        "performance in terms of accuracy, precision, recall, and F1-score. Use these results as the baseline"
      ],
      "metadata": {
        "id": "DBPw1sz_uI51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# We create the Dummy Classifier\n",
        "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "# We train the model with the data preprocessed\n",
        "dummy_classifier.fit(X_train_vectorized, y_train_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "cucat4qNuOXW",
        "outputId": "d955f341-15be-4ca4-ec11-0915b9da591b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(strategy='most_frequent')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}