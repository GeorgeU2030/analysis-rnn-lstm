{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUUeug0tMaBf2zuszd6SvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeU2030/analysis-rnn-lstm/blob/main/code-implementation/RNN_LSTM_TI2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment analysis - RNN and LSTM.\n",
        "\n",
        "Members\n",
        "\n",
        "- Luis Botero\n",
        "- Juan Medina\n",
        "- George Trujillo"
      ],
      "metadata": {
        "id": "eaUvW-UHtAMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Gather the dataset for sentiment analysis from the UCI Machine Learning Repository, specifically\n",
        "the Sentiment Labelled Sentences Data Set"
      ],
      "metadata": {
        "id": "FnidrNccQzat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the file from the download site\n",
        "!wget https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
        "\n",
        "# Unzip the obtained file\n",
        "!unzip sentiment+labelled+sentences.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hZnPbwQywX",
        "outputId": "b7b97028-29ca-4c42-b28a-4b935bc1ef8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-19 16:46:46--  https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘sentiment+labelled+sentences.zip’\n",
            "\n",
            "sentiment+labelled+     [ <=>                ]  82.21K   448KB/s    in 0.2s    \n",
            "\n",
            "2023-11-19 16:46:47 (448 KB/s) - ‘sentiment+labelled+sentences.zip’ saved [84188]\n",
            "\n",
            "Archive:  sentiment+labelled+sentences.zip\n",
            "   creating: sentiment labelled sentences/\n",
            "  inflating: sentiment labelled sentences/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/sentiment labelled sentences/\n",
            "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: __MACOSX/._sentiment labelled sentences  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocess the text data, including tokenization, lowercasing, and removing stopwords. Prepare the\n",
        "data for supervised learning (use NLTK)."
      ],
      "metadata": {
        "id": "XNbnxgJZdda3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# We load the data from the websites\n",
        "# amazon\n",
        "df_amazon = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep='\\t', header=None)\n",
        "df_amazon.columns = ['sentence', 'label']\n",
        "\n",
        "# imdb\n",
        "df_imdb = pd.read_csv('sentiment labelled sentences/imdb_labelled.txt', sep='\\t', header=None)\n",
        "df_imdb.columns = ['sentence', 'label']\n",
        "\n",
        "# yelp\n",
        "df_yelp = pd.read_csv('sentiment labelled sentences/yelp_labelled.txt', sep='\\t', header=None)\n",
        "df_yelp.columns = ['sentence', 'label']\n",
        "\n",
        "# We mix the dataframes, reload the index, for no obtain duplicate indexes\n",
        "df = pd.concat([df_amazon, df_imdb, df_yelp], ignore_index=True)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "NV-rUa39dbw7",
        "outputId": "577cd3c8-f130-478b-abde-3e401d60dab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               sentence  label\n",
            "0     So there is no way for me to plug it in here i...      0\n",
            "1                           Good case, Excellent value.      1\n",
            "2                                Great for the jawbone.      1\n",
            "3     Tied to charger for conversations lasting more...      0\n",
            "4                                     The mic is great.      1\n",
            "...                                                 ...    ...\n",
            "2743  I think food should have flavor and texture an...      0\n",
            "2744                           Appetite instantly gone.      0\n",
            "2745  Overall I was not impressed and would not go b...      0\n",
            "2746  The whole experience was underwhelming, and I ...      0\n",
            "2747  Then, as if I hadn't wasted enough of my life ...      0\n",
            "\n",
            "[2748 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}